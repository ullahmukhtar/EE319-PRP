{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Some LaTeX definitions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "$$\\newcommand{\\diff}{\\mathop{}\\!\\mathrm{d}}\n",
       "\\DeclareMathOperator{\\Diff}{D}\n",
       "\\newcommand{\\euler}{\\mathrm{e}}\n",
       "\\DeclareMathOperator{\\EE}{E}\n",
       "\\DeclareMathOperator{\\Var}{Var}\n",
       "\\DeclareMathOperator{\\Cov}{Cov}\n",
       "\\DeclareMathOperator{\\Ber}{Ber}\n",
       "\\DeclareMathOperator{\\Bin}{Bin}\n",
       "\\DeclareMathOperator{\\NB}{NB}\n",
       "\\DeclareMathOperator{\\Geo}{Geo}\n",
       "\\DeclareMathOperator{\\HG}{HG}\n",
       "\\DeclareMathOperator{\\Poi}{Poi}\n",
       "\\DeclareMathOperator{\\Ud}{Ud}\n",
       "\\DeclareMathOperator{\\U}{U}\n",
       "\\DeclareMathOperator{\\ind}{\\mathbf{1}}\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#HIDDEN\n",
    "%run nbinitex.ipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "graffitiCellId": "id_0m3re3b"
   },
   "source": [
    "# EE319 - Probability & Random Processes\n",
    "## *Dr.-Ing. Mukhtar Ullah*, FAST NUCES, Spring 2020\n",
    "<hr>\n",
    "\n",
    "## **Lecture 19** (2020-04-xx)\n",
    "## Expectation (continued)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "graffitiCellId": "id_ou7x9gu"
   },
   "source": [
    "#### Expectation of a transformed RV\n",
    "Consider a transformation $Y=g\\left(X\\right)$ where $g$ is a point function making any value $x$ of $X$ to the value $g\\left(x\\right)$ of $Y$. How are the two expectations $\\EE X$ and $\\EE Y$ related? Let us work that out for the easier case of discrete distribution first. Any value $x$ of $X$ determines the value $y$ of $Y$ according\n",
    "to $y=g\\left(x\\right)$. Since both the RVs are defined on the same probability space, the following correspondence between events is evident\n",
    "\\\\[\n",
    "\\left(Y=k\\right)=\\left(g\\left(X\\right)=k\\right)=\\bigcup_{g\\left(i\\right)=k}\\left(X=i\\right)\n",
    "\\\\]\n",
    "The expectation of $Y$ then follows from the law of total probability:\n",
    "\\\\[\n",
    "\\EE Y=\\sum_{k\\in\\mathcal{Y}}kf_{Y}\\left(k\\right)=\\sum_{k\\in\\mathcal{Y}}kP\\left(Y=k\\right)=\\sum_{k\\in\\mathcal{Y}}k\\sum_{g\\left(i\\right)=k}P\\left(X=i\\right)=\\sum_{i\\in\\mathcal{X}}g\\left(i\\right)f_{X}\\left(k\\right)\n",
    "\\\\]\n",
    "In other words, we do not need the distribution of $Y$ to compute the expectation. This makes sense in terms of long-run relative frequencies: the observed long-run frequency of a value $x$ is also the frequency of $g\\left(x\\right)$.\n",
    "\n",
    "This result can be extended to general RVs. The pre-image of any Borel\n",
    "set $\\mathsf{B}$ can be expressed as a disjoint union\n",
    "\\\\[\n",
    "Y^{-1}\\left[\\diff\\mathsf{B}_{y}\\right]=\\bigcup_{g\\left(x\\right)=y}X^{-1}\\left[\\diff\\mathsf{B}_{x}\\right]\n",
    "\\\\]\n",
    "The expectation of $Y$ then follows from the law of total probability:\n",
    "\\\\[\n",
    "\\EE Y=\\intop_{\\mathbb{R}}yP_{Y}\\left(\\diff\\mathsf{B}_{y}\\right)=\\intop_{\\mathbb{R}}y\\sum_{g\\left(x\\right)=y}P_{X}\\left(\\diff\\mathsf{B}_{x}\\right)=\\intop_{\\mathbb{R}}g\\left(x\\right)P_{X}\\left(\\diff\\mathsf{B}_{x}\\right)\n",
    "\\\\]\n",
    "This leads to a more general definition of the expectation:\n",
    "\\\\[\n",
    "\\EE g\\left(X\\right)=\\intop_{\\mathbb{R}}g\\left(x\\right)P_{X}\\left(\\diff\\mathsf{B}_{x}\\right)\n",
    "\\\\]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "graffitiCellId": "id_6d97bnd"
   },
   "source": [
    "#### Linearity of the expectation (simpler)\n",
    "Recall from math and circuit courses that integration and summation are linear operations. You can verify from the above definition that the expectation inherits linearity from integration and summation in the following sense:\n",
    "$$\n",
    "\\EE \\left(aX+b\\right)=a\\EE X+\\EE b=a\\EE X+b\n",
    "$$\n",
    "Setting $a=1$ and $b=-\\mu_{X}$ gives \n",
    "$$\n",
    "\\EE \\left(X-\\mu_{X}\\right)=\\EE X-\\mu_{X}=0\n",
    "$$\n",
    "as expected.\n",
    "\n",
    "Two examples can be worked out here.\n",
    ">**The two-point distribution**\n",
    ">Since we know the mean of the Bernoulli RV $X\\sim\\Ber_{p}$ is $p$, the mean of the transformed (two-point) RV $Y=a+\\left(b-a\\right)X$ follows from linearity\n",
    "\\\\[\n",
    "\\EE Y=a+\\left(b-a\\right)\\EE X=a+\\left(b-a\\right)p=\\left(1-p\\right)a+pb\n",
    "\\\\]\n",
    ">**The discrete uniform distribution (transformed)**\n",
    ">Since we know the mean of the standard discrete uniform RV $X\\sim\\Ud_{n}$, the mean of the transformed RV $Y=a-1+X$ follows from linearity\n",
    "\\\\[\n",
    "\\EE Y=a-1+\\EE X=a-1+\\left.\\frac{n+1}{2}\\right|_{n=b-a+1}=a-1+\\frac{b-a+2}{2}=\\frac{a+b}{2}\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Linearity of the expectation (detailed)\n",
    "A natural question arises in a curious mind here: why did we not try to define linearity of the expectation by this equation\n",
    "\\\\[\n",
    "\\EE\\left(aX+bY\\right)=a\\EE X+b\\EE Y\n",
    "\\\\]\n",
    "which is very reasonable to expect. To see the complication in this seemingly innocent equation, assume $X$ and $Y$ to be discrete, for convenience, and define a new RV $Z=aX+bY$ as a linear transformation. Any pair $\\left(x,y\\right)$ of values of $\\left(X,Y\\right)$ determines the value $z$ of $Z$ according to $z=ax+by$. Since all the three RVs are defined on the same probability space, the following correspondence between events is evident: \n",
    "\\\\[\n",
    "\\left(Z=k\\right)=\\left(aX+bY=k\\right)=\\bigcup_{ai+bj=k}\\left(X=i\\cap Y=j\\right)\n",
    "\\\\]\n",
    "The expectation of $Z$ then follows from the law of total probability:\n",
    "\\begin{align*}\n",
    "\\EE Z=\\sum_{k\\in\\mathcal{Z}}kP\\left(Z=k\\right) & =\\sum_{k\\in\\mathcal{Z}}k\\sum_{ai+bj=k}P\\left(X=i\\cap Y=j\\right)\\\\\n",
    " & =\\sum_{i\\in\\mathcal{X}}\\sum_{j\\in\\mathcal{Y}}\\left(ai+bj\\right)P_{X,Y}\\left(\\left\\{ i\\right\\} \\times\\left\\{ j\\right\\} \\right)\\\\\n",
    " & =a\\sum_{i\\in\\mathcal{X}}i\\sum_{j\\in\\mathcal{Y}}P_{X,Y}\\left(\\left\\{ i\\right\\} \\times\\left\\{ j\\right\\} \\right)+b\\sum_{j\\in\\mathcal{Y}}j\\sum_{i\\in\\mathcal{X}}P_{X,Y}\\left(\\left\\{ i\\right\\} \\times\\left\\{ j\\right\\} \\right)\\\\\n",
    " & =a\\sum_{i\\in\\mathcal{X}}iP_{X}\\left(\\left\\{ i\\right\\} \\right)+b\\sum_{j\\in\\mathcal{Y}}jP_{Y}\\left(\\left\\{ j\\right\\} \\right)\\\\\n",
    " & =a\\EE X+b\\EE Y\n",
    "\\end{align*}\n",
    "This result can be extended to general RVs. The pre-image of any Borel set $\\mathsf{B}$ of the $z$-axis can be expressed as a disjoint\n",
    "union\n",
    "\\\\[\n",
    "Z^{-1}\\left[\\diff \\mathsf{B}_{z}\\right]=\\bigcup_{ax+by=z}X^{-1}\\left[\\diff \\mathsf{B}_{x}\\right]\\cap Y^{-1}\\left[\\diff \\mathsf{B}_{y}\\right]\n",
    "\\\\]\n",
    "The expectation of $Z$ then follows from the law of total probability:\n",
    "\\begin{align*}\n",
    "\\EE Z=\\intop_{\\mathbb{R}}zP_{Z}\\left(\\diff \\mathsf{B}_{z}\\right) & =\\intop_{\\mathbb{R}}z\\intop_{ax+by=z}P_{X,Y}\\left(\\diff \\mathsf{B}_{x}\\times\\diff \\mathsf{B}_{y}\\right)\\\\\n",
    " & =\\intop_{\\mathbb{R}}\\intop_{\\mathbb{R}}\\left(ax+by\\right)P_{X,Y}\\left(\\diff \\mathsf{B}_{x}\\times\\diff \\mathsf{B}_{y}\\right)\\\\\n",
    " & =a\\intop_{\\mathbb{R}}x\\intop_{\\mathbb{R}}P_{X,Y}\\left(\\diff \\mathsf{B}_{x}\\times\\diff \\mathsf{B}_{y}\\right)+b\\intop_{\\mathbb{R}}y\\intop_{\\mathbb{R}}P_{X,Y}\\left(\\diff \\mathsf{B}_{x}\\times\\diff \\mathsf{B}_{y}\\right)\\\\\n",
    " & =a\\intop_{\\mathbb{R}}xP_{X}\\left(\\diff \\mathsf{B}_{x}\\right)+b\\intop_{\\mathbb{R}}yP_{Y}\\left(\\diff \\mathsf{B}_{y}\\right)\\\\\n",
    " & =a\\EE X+b\\EE Y\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "graffitiCellId": "id_pb82llw"
   },
   "source": [
    "#### Spread of a distribution\n",
    "A measure of spread of a distribution is the so-called standard deviation, denoted $\\sigma$, which can be viewed as the Euclidean distance between a typical pair of values in a distribution. The mean was introduced as a typical value in the sense of minimizing the sum of its squared Euclidean distances from long-run observations. That gives us a hint of an estimate $\\hat{\\sigma}_{n}^{2}$ of the squared standard deviation--the average squared distance per trial, \n",
    "$$\n",
    "\\hat{\\sigma}_{n}^{2}=\\frac{1}{n}S\\left(\\hat{\\mu}_{n}\\right)=\\frac{1}{n}\\sum_{k\\in\\mathcal{X}^{\\#}}\\left(k-\\hat{\\mu}_{n}\\right)^{2}a_{n}\\left(k\\right)=\\sum_{k\\in\\mathcal{X}^{\\#}}\\left(k-\\hat{\\mu}_{n}\\right)^{2}r_{n}\\left(k\\right)\n",
    "$$\n",
    "To see why $\\hat{\\sigma}_{n}$ is the Euclidean distance between a\n",
    "typical pair of values, note that both $\\left(\\hat{\\mu}_{n},\\hat{\\mu}_{n}+\\hat{\\sigma}_{n}\\right)$\n",
    "and $\\left(\\hat{\\mu}_{n},\\hat{\\mu}_{n}-\\hat{\\sigma}_{n}\\right)$ can\n",
    "be viewed as typical pairs because\n",
    "\\\\[\n",
    "\\left(\\hat{\\mu}_{n}\\pm\\hat{\\sigma}_{n}-\\hat{\\mu}_{n}\\right)^{2}=\\hat{\\sigma}_{n}^{2}\n",
    "\\\\]\n",
    "That leads us to define the standard deviation $\\sigma$ of a discrete distribution as the positive square root of what is called the variance of the distribution,\n",
    "$$\n",
    "\\sigma^{2}=\\sum_{k\\in\\mathcal{X}^{\\#}}\\left(k-\\hat{\\mu}\\right)^{2}p_{k}\n",
    "$$\n",
    "The variance of a general RV $X$, denoted $\\Var X$,\n",
    "is defined by\n",
    "$$\n",
    "\\sigma_{X}^{2}=\\Var X=\\EE \\left(X-\\mu_{X}\\right)^{2}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Nonlinearity of variance (simpler)\n",
    "The squared deviation in the above formula prevents the variance operator\n",
    "to inherit linearity from integration and summation. We can study\n",
    "the nature of nonlinearity of variance by considering a linear transformation\n",
    "$Y=aX+b$ of a RV $X$ whose variance is known. Correspondence between\n",
    "values and means take the form\n",
    "\\\\[\n",
    "y=ax+b,\\quad\\mu_{Y}=a\\mu_{X}+b\n",
    "\\\\]\n",
    "This all leads to \n",
    "\\\\[\n",
    "\\Var Y=\\EE\\left(Y-\\mu_{Y}\\right)^{2}=\\EE\\left(aX+b-a\\mu_{X}-b\\right)^{2}=\\EE a^{2}\\left(X-\\mu_{X}\\right)^{2}=a^{2}\\Var X\n",
    "\\\\]\n",
    "As we expected, $\\Var\\left(aX+b\\right)\\ne a\\Var X+b$ thanks to the\n",
    "nonlinearity of variance.\n",
    "\n",
    "### Nonlinearity of variance (detailed)\n",
    "Consider a linear transformation $Z=aX+bY$ of two RVs with known\n",
    "variances. Correspondence between values and means take the form\n",
    "\\\\[\n",
    "z=ax+by,\\quad\\mu_{Z}=a\\mu_{X}+b\\mu_{Y}\n",
    "\\\\]\n",
    "This all leads to \n",
    "\\begin{align*}\n",
    "\\Var Z=\\EE\\left(Z-\\mu_{Z}\\right)^{2} & =\\EE\\left(aX+bY-a\\mu_{X}-b\\mu_{Y}\\right)^{2}\\\\\n",
    " & =a^{2}\\EE\\left(X-\\mu_{X}\\right)^{2}+b^{2}\\EE\\left(Y-\\mu_{Y}\\right)^{2}+ab\\EE\\left(X-\\mu_{X}\\right)\\left(Y-\\mu_{Y}\\right)\\\\\n",
    " & =a^{2}\\Var X+b^{2}\\Var Y+ab\\EE\\left(X-\\mu_{X}\\right)\\left(Y-\\mu_{Y}\\right)\n",
    "\\end{align*}\n",
    "As we expected, $\\Var\\left(aX+bY\\right)\\ne a\\Var X+b\\Var Y$ thanks\n",
    "to the nonlinearity of variance. The last term in the above equation\n",
    "involves what is called the covariance between two RVs:\n",
    "\\\\[\n",
    "\\Cov\\left(X,Y\\right)=\\EE\\left(X-\\mu_{X}\\right)\\left(Y-\\mu_{Y}\\right)\n",
    "\\\\]\n",
    "Let us work out the variance for the two RVs discussed above."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

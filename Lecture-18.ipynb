{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... Some LaTeX definitions\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "$$\\newcommand{\\diff}{\\mathop{}\\!\\mathrm{d}}\n",
       "\\DeclareMathOperator{\\Diff}{D}\n",
       "\\newcommand{\\euler}{\\mathrm{e}}\n",
       "\\DeclareMathOperator{\\EE}{E}\n",
       "\\DeclareMathOperator{\\Var}{Var}\n",
       "\\DeclareMathOperator{\\Cov}{Cov}\n",
       "\\DeclareMathOperator{\\Ber}{Ber}\n",
       "\\DeclareMathOperator{\\Bin}{Bin}\n",
       "\\DeclareMathOperator{\\NB}{NB}\n",
       "\\DeclareMathOperator{\\Geo}{Geo}\n",
       "\\DeclareMathOperator{\\HG}{HG}\n",
       "\\DeclareMathOperator{\\Poi}{Poi}\n",
       "\\DeclareMathOperator{\\Ud}{Ud}\n",
       "\\DeclareMathOperator{\\U}{U}\n",
       "\\DeclareMathOperator{\\ind}{\\mathbf{1}}\n",
       "$$\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#HIDDEN\n",
    "%run nbinitex.ipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "graffitiCellId": "id_0m3re3b"
   },
   "source": [
    "# EE319 - Probability & Random Processes\n",
    "## *Dr.-Ing. Mukhtar Ullah*, FAST NUCES, Spring 2020\n",
    "<hr>\n",
    "\n",
    "## **Lecture 18** (2020-04-xx)\n",
    "## Several-point distribution (continued)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Throw of two dice\n",
    "Recall the two-dice throw experiment with sample space\n",
    "\\\\[\n",
    "\\mathsf{\\Omega}=\\left[1\\cdot\\cdot6\\right]^{2}=\\left[1\\cdot\\cdot6\\right]\\times\\left[1\\cdot\\cdot6\\right]\n",
    "\\\\]\n",
    "and two partitions as illustrated below.\n",
    "<center><img src=\"images/two_dice_partition_wrt_sum.png\" width=\"70%\"></center>\n",
    "    \n",
    "The partition on the left is a detailed one. Say our interest lies in the total number of dots facing up on both dice.\n",
    "    \n",
    "Events of interest\n",
    "\\\\[\n",
    "\\mathsf{A}_{k}=\\left\\{ \\left(i,k-i\\right)\\mid i,,k-i\\in\\left[1\\cdot\\cdot6\\right]\\right\\} ,\\quad k\\in\\left[2\\cdot\\cdot12\\right]\n",
    "\\\\]\n",
    "Probabilities\n",
    "\\\\[\n",
    "p_{k}=P\\left(\\mathsf{A}_{k}\\right)=\\frac{\\left|\\mathsf{A}_{k}\\right|}{\\left|\\mathsf{\\Omega}\\right|}=\\begin{cases}\n",
    "\\dfrac{k-1}{36} & k\\in\\left[2\\cdot\\cdot7\\right]\\\\\n",
    "\\dfrac{13-k}{36} & k\\in\\left[8\\cdot\\cdot12\\right]\n",
    "\\end{cases}\n",
    "\\\\]\n",
    "Define the appropriate RV\n",
    "\\\\[\n",
    "X=\\sum_{k=2}^{12}k\\ind_{\\mathsf{A}_{k}},\\quad X\\left[\\mathsf{A}_{k}\\right]=\\left\\{ k\\right\\} ,\\quad k\\in\\left[2\\cdot\\cdot12\\right]\n",
    "\\\\]\n",
    "Induced probability measure\n",
    "\\\\[\n",
    "P_{X}=\\sum_{k=1}^{n}p_{k}\\delta_{k}\n",
    "\\\\]\n",
    "Induced probability distribution\n",
    "\\\\[\n",
    "\\mathcal{X}=\\left[2\\cdot\\cdot12\\right],\\quad f_{X}^{\\#}\\left(k\\right)=p_{k},\\quad F_{X}^{\\#}\\left(k\\right)=\\sum_{i=2}^{k}p_{i}\n",
    "\\\\]\n",
    "PDF and CDF\n",
    "\\begin{align*}\n",
    "f_{X}\\left(x\\right) & =f_{X}^{\\#}\\left(x\\right)\\left[x\\in\\left[2\\cdot\\cdot12\\right]\\right]\\\\\n",
    "F_{X}\\left(x\\right) & =F_{X}^{\\#}\\left(\\min\\left\\{ 12,\\left\\lfloor x\\right\\rfloor \\right\\} \\right)\\left[x\\ge2\\right]\n",
    "\\end{align*}\n",
    "\n",
    "This was the distribution included in the very first lecture.\n",
    "    \n",
    "<center><img src=\"images/chance_regularity_histogram.png\" width=\"50%\"></center>\n",
    "\n",
    "Explain in your own words the pattern in this histogram in light of the PDF above.\n",
    "\n",
    "This example motivates a general formulation of a discrete distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Generic discrete distribution\n",
    "Consider a probability space $\\left(\\mathsf{\\Omega},\\mathcal{F},P\\right)$\n",
    "with the event space $\\mathcal{F}=\\sigma\\left(\\mathcal{C}\\right)$\n",
    "generated by a partition $\\mathcal{C}=\\left\\{ \\mathsf{A}_{k}\\mid k\\in\\mathcal{K}\\right\\} $\n",
    "of the outcome space $\\mathsf{\\Omega}$, and a discrete probability\n",
    "measure $P$ defined by $P\\left(\\mathsf{A}_{k}\\right)=p_{k}$ for\n",
    "all indices $k\\in\\mathcal{K}$. Any RV $X$ definable on $\\mathsf{\\Omega}$\n",
    "with respect to $\\mathcal{F}$ must assign same value, say $k$, to\n",
    "all points in $\\mathsf{A}_{k}$ but different from other values $j$.\n",
    "Mathematically, the definition of $X$ reads\n",
    "\\\\[\n",
    "X=\\sum_{k\\in\\mathcal{K}}k\\mathbf{1}_{\\mathsf{A}_{k}},\\quad X\\left[\\mathsf{A}_{k}\\right]=\\left\\{ k\\right\\} ,\\quad k\\in\\mathcal{K}\n",
    "\\\\]\n",
    "Following a procedure similar to that for other cases above, the generic\n",
    "discrete measure can be shown to take the form\n",
    "\\\\[\n",
    "P_{X}=\\sum_{k\\in\\mathcal{K}}p_{k}\\delta_{k}\n",
    "\\\\]\n",
    "That $X$ follows a discrete distribution is written as $X\\sim\\sum_{k\\in\\mathcal{K}}p_{k}\\delta_{k}$\n",
    "with the following characterization:\n",
    "\\\\[\n",
    "\\mathcal{X}=\\mathcal{K},\\ f_{X}^{\\#}\\left(k\\right)=p_{k},\\ F_{X}^{\\#}\\left(k\\right)=\\sum_{i\\in\\mathcal{X}}p_{k}\\left[i\\le k\\right]\n",
    "\\\\]\n",
    "The PDF and CDF can then be recovered.\n",
    "\\\\[\n",
    "f_{X}\\left(x\\right)=f_{X}^{\\#}\\left(x\\right)\\left[x\\in\\mathcal{X}\\right],\\ F_{X}\\left(x\\right)=F_{X}^{\\#}\\left(\\max\\mathcal{X}_{\\le x}\\right)\\left[\\mathcal{X}_{\\le x}\\ne\\emptyset\\right]\n",
    "\\\\]\n",
    "\n",
    "An illustration of the generic discrete RV will help.\n",
    "<center><img src=\"images/discrete_rv_mapping.png\" width=\"80%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Bit transmission\n",
    "Recall the bit transmission problem illustrated here. \n",
    "<center><img src=\"images/bit_transmission.png\" width=\"50%\"></center>\n",
    "\n",
    "The input bit is modeled by a Bernoulli RV $X\\sim\\Ber_{1-p}$. The output bit is also a Bernoulli RV but with a parameter that we need to find. The diagram encodes the following conditional probabilities.\n",
    "\\begin{align*}\n",
    "P\\left(Y=1\\mid X=0\\right) & =P\\left(Y=0\\mid X=1\\right)=\\epsilon\\\\\n",
    "P\\left(Y=1\\mid X=1\\right) & =P\\left(Y=0\\mid X=0\\right)=1-\\epsilon\n",
    "\\end{align*}\n",
    "The law of total probability allows to write \n",
    "\\begin{align*}\n",
    "P\\left(Y=1\\right) & =P\\left(X=0\\right)P\\left(Y=1\\mid X=0\\right)+P\\left(X=1\\right)P\\left(Y=1\\mid X=1\\right)=p\\epsilon+\\left(1-p\\right)\\left(1-\\epsilon\\right)\\\\\n",
    "P\\left(Y=0\\right) & =P\\left(X=0\\right)P\\left(Y=0\\mid X=0\\right)+P\\left(X=1\\right)P\\left(Y=0\\mid X=1\\right)=p\\left(1-\\epsilon\\right)+\\left(1-p\\right)\\epsilon\n",
    "\\end{align*}\n",
    "Therefore, $Y\\sim\\Ber_{\\theta}$ where $\\theta=p\\epsilon+\\left(1-p\\right)\\left(1-\\epsilon\\right)$.\n",
    "\n",
    "The bit error is represented by the Borel set (in the 2-D plane)\n",
    "\\\\[\n",
    "\\mathsf{B}=\\left\\{ \\left(0,1\\right),\\left(1,0\\right)\\right\\} \n",
    "\\\\]\n",
    "with pre-image\n",
    "\\\\[\n",
    "\\mathsf{A}=\\left(Y=1,X=0\\right)\\cup\\left(Y=0,X=1\\right)\n",
    "\\\\]\n",
    "and the resulting bit-error probability \n",
    "\\\\[\n",
    "P\\left(\\mathsf{A}\\right)=P\\left(Y=1,X=0\\right)+P\\left(Y=0,X=1\\right)=p\\epsilon+\\left(1-p\\right)\\epsilon=\\epsilon\n",
    "\\\\]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "graffitiCellId": "id_jg2qy00"
   },
   "source": [
    "#### Typical value of a distribution\n",
    "Consider a discrete distribution with values $k\\in\\mathcal{X}^{\\#}$ and probabilities $p_{k}$. If the distribution is symmetrical about a single peak, then the most likely value, called the mode, can be considered a typical value. For distributions of other shapes, the mode may not be appropriate. Other alternatives include the median and the mean. The median $m$ of a distribution generalizes the notion of middle value and is defined as the value at which the CDF equals $1/2$. The mean $\\mu$ of a distribution is the value that best fits long-run observations in a least squared sense.\n",
    "\n",
    "<img src=\"images/chance_regularity_t-plot.png\" width=\"50%\" />\n",
    "\n",
    "We can get an estimate $\\hat{\\mu}_{n}$ of the mean based on the sum of its squared Euclidean distances from observations in $n$ trials of the underlying experiment, treated as a function of $\\hat{\\mu}_{n}$,\n",
    "$$\n",
    "S\\left(\\hat{\\mu}_{n}\\right)=\\sum_{k\\in\\mathcal{X}^{\\#}}\\left(k-\\hat{\\mu}_{n}\\right)^{2}a_{n}\\left(k\\right)\n",
    "$$\n",
    "where $a_{n}\\left(k\\right)$ is the observed frequency of $k$ in $n$ trials. Note that absolute frequencies must add up to $n$. Since $\\hat{\\mu}_{n}$ minimizes $S\\left(\\hat{\\mu}_{n}\\right)$ by definition, we require $S^{\\prime}\\left(\\hat{\\mu}_{n}\\right)=0$ which leads to\n",
    "$$\n",
    "-2\\sum_{k\\in\\mathcal{X}^{\\#}}\\left(k-\\hat{\\mu}_{n}\\right)a_{n}\\left(k\\right)=0\\implies n\\hat{\\mu}_{n}=\\sum_{k\\in\\mathcal{X}^{\\#}}ka_{n}\\left(k\\right)\\implies\\hat{\\mu}_{n}=\\frac{1}{n}\\sum_{k\\in\\mathcal{X}^{\\#}}ka_{n}\\left(k\\right)=\\sum_{k\\in\\mathcal{X}^{\\#}}kr_{n}\\left(k\\right)\n",
    "$$\n",
    "where $r_{k}\\left(n\\right)$ is the relative frequency of $k$ in $n$ trials. Since the long-run relative frequencies $r_{n}\\left(k\\right)$ approach probabilities $p_{k}$, we have the following formula for the mean of a discrete distribution\n",
    "$$\n",
    "\\mu=\\sum_{k\\in\\mathcal{X}^{\\#}}kp_{k}\n",
    "$$\n",
    "This makes sense as each value $x_{i}$ of the RV $X$ is weighted by the associated probability $p_{i}$. Owing to this probability weighting, the mean is also called the expected value, or expectation, of the RV. The expectation of a RV $X$, denoted by $\\EE X$, is defined by\n",
    "$$\n",
    "\\mu_{X}=\\EE X=\\intop_{\\mathbb{R}}xP_{X}\\left(\\diff \\mathsf{B}_{x}\\right)=\\sum_{k\\in\\mathcal{X}^{\\#}}kf^{\\#}_{X}\\left(k\\right)+\\intop_{\\mathcal{X}}xf^{\\wedge}_{X}\\left(x\\right)\\diff x\n",
    "$$\n",
    "Note that the expectation is not a point function like a transformation. Instead, the expectation is an example of what is called an operator. An operator takes a function and returns another function. A special kind of an operator, called a functional, collapses a function to a number. You can now see that the expectation operator acts on a RV, a function, and returns the mean, a number. Thus, the expectation operator is a functional. The notation $\\EE X$ without using any brackets not only reminds of the operator involved but also helps to distinguish it from a transformation $g\\left(X\\right)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let us work out the mean for the two RVs discussed above.\n",
    "\n",
    ">**Dirac distribution**\n",
    ">The mean of the deterministic RV $a\\sim\\delta_{a}$ is\n",
    "$$\n",
    "\\EE a=\\sum_{k\\in\\left\\{ a\\right\\} }k\\delta_{a}\\left(\\left\\{ k\\right\\} \\right)=a\n",
    "$$\n",
    "In other words, the expected value of a (deterministic) constant is the constant itself.\n",
    "\n",
    ">**Bernoulli distribution**\n",
    ">The mean of the Bernoulli RV $X\\sim\\Ber_{p}$ is\n",
    "$$\n",
    "\\EE X=\\sum_{k=0}^{1}k\\mathrm{Ber}\\left(k;p\\right)=\\sum_{k=0}^{1}kp^{k}\\left(1-p\\right)^{1-k}=p\n",
    "$$\n",
    "\n",
    ">**Discrete uniform distribution (standard)**\n",
    ">The mean of the discrete uniform RV $X\\sim\\Ud_{n}$ is\n",
    "\\\\[\n",
    "\\mu_{X}=\\EE X=\\sum_{k=1}^{n}k\\Ud\\left(k;n\\right)=\\frac{1}{n}\\sum_{k=1}^{n}k=\\frac{n+1}{2}\n",
    "\\\\]\n",
    ">**Mean number of dots facing up on two dice**\n",
    "Recall the throw of two dice and the RV $X$ representing the number\n",
    "of dots facing up on both the dice. \n",
    "\\begin{align*}\n",
    "\\mu_{X}=\\EE X & =\\sum_{k=2}^{12}kp_{k}\\\\\n",
    " & =\\sum_{k=2}^{7}k\\left(\\frac{k-1}{36}\\right)+\\sum_{k=8}^{12}k\\left(\\frac{13-k}{36}\\right)\\\\\n",
    " & =\\frac{1}{36}\\left[\\sum_{k=2}^{7}k\\left(k-1\\right)+12\\sum_{k=8}^{12}k-\\sum_{k=8}^{12}k\\left(k-1\\right)\\right]\n",
    "\\end{align*}\n",
    "These seemingly intractable sums can be reduced by employing what is called the forward difference operator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Forward difference operator\n",
    "The forward difference operator, denoted $\\Delta$, is defined by\n",
    "its action on a sequence, namely\n",
    "\\\\[\n",
    "\\Delta s_{k}=s_{k+1}-s_{k}\n",
    "\\\\]\n",
    "Essentially, it is a shift operator. We will now investigate the behavior\n",
    "of the relevant polynomials under $\\Delta$. \n",
    "\n",
    "1. Quadratic falling factorial\n",
    "\\\\[\n",
    "\\Delta\\left(k\\right)_{2}=\\Delta\\left[k\\left(k-1\\right)\\right]=\\left(k+1\\right)k-k\\left(k-1\\right)=2k\n",
    "\\\\]\n",
    "which can be exploited to get a formula for the integer sum \n",
    "\\\\[\n",
    "\\sum_{k=1}^{n}k=\\frac{1}{2}\\sum_{k=1}^{n}\\Delta\\left(k\\right)_{2}=\\frac{\\left(n+1\\right)_{2}-\\left(1\\right)_{2}}{2}=\\frac{\\left(n+1\\right)n}{2}\n",
    "\\\\]\n",
    "1. Cubic falling factorial\n",
    "\\\\[\n",
    "\\Delta\\left(k\\right)_{3}=\\Delta\\left[k\\left(k-1\\right)\\left(k-2\\right)\\right]=\\left(k+1\\right)k\\left(k-1\\right)-k\\left(k-1\\right)\\left(k-2\\right)=3k\\left(k-1\\right)\n",
    "\\\\]\n",
    "which can be exploited to get another useful sum \n",
    "\\\\[\n",
    "\\sum_{k=2}^{n}k\\left(k-1\\right)=\\frac{1}{3}\\sum_{k=2}^{n}\\Delta\\left(k\\right)_{3}=\\frac{\\left(n+1\\right)_{3}-\\left(2\\right)_{3}}{3}=\\frac{n\\left(n^{2}-1\\right)}{3}\n",
    "\\\\]\n",
    "We will use these identities to evaluate the sums in the foregoing expectation. \n",
    ">**Mean number of dots facing up on two dice (continued)**\n",
    ">The integer sums:\n",
    "\\begin{align*}\n",
    "\\sum_{k=1}^{12}k & =\\frac{13\\times 12}{2}=78\\\\\n",
    "\\sum_{k=1}^{7}k & =\\frac{8\\times 7}{2}=28\\\\\n",
    "\\sum_{k=8}^{12}k & =78-28=50\n",
    "\\end{align*}\n",
    "The quadratic falling factorial sums\n",
    "\\begin{align*}\n",
    "\\sum_{k=2}^{12}k\\left(k-1\\right) & =\\frac{12\\left(12^{2}-1\\right)}{3}=572\\\\\n",
    "\\sum_{k=2}^{7}k\\left(k-1\\right) & =\\frac{7\\left(7^{2}-1\\right)}{3}=112\\\\\n",
    "\\sum_{k=8}^{12}k\\left(k-1\\right) & =572-112=460\n",
    "\\end{align*}\n",
    "Putting it all together yields the required expectation in the twice\n",
    "dice-throw problem,\n",
    "\\\\[\n",
    "\\mu_{X}=\\EE X=\\frac{1}{36}\\left[112+12\\times 50-460\\right]=7\n",
    "\\\\]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
